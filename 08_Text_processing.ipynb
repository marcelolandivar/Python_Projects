{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_a2hajcA99-K"
   },
   "source": [
    "![BTS](https://github.com/vfp1/bts-mbds-data-science-foundations-2019/blob/master/sessions/img/Logo-BTS.jpg?raw=1)\n",
    "\n",
    "# Session 8: Text processing - Introduction to Spacy\n",
    "\n",
    "### Victor F. Pajuelo Madrigal <victor.pajuelo@bts.tech> - Data Science Foundations (2019-10-17)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vfp1/bts-mbds-data-science-foundations-2019/blob/master/sessions/08_Text_processing.ipynb)\n",
    "\n",
    "**Resources:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTIcPknwQz5z"
   },
   "source": [
    "# Spacy installation\n",
    "\n",
    "```\n",
    "$ conda activate bts36\n",
    "$ conda install -c conda-forge spacy\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oabpc-xuVxAQ"
   },
   "source": [
    "# Spacy introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QHBivImfOvp"
   },
   "source": [
    "## Import language models \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "$ python -m spacy download en_core_web_sm\n",
    "$ python -m spacy download en\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "nPv81PAORYB7",
    "outputId": "1604fba5-07fc-4c25-d486-8d2fdd2cf623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from en_core_web_sm==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.17.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.2.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.36.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.8)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "8mQRg-8jfzDI",
    "outputId": "fde47e21-fdaf-41ae-8dea-cf6321d1ade4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from en_core_web_sm==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.17.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.2.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.36.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmwJHdwEU4uM"
   },
   "source": [
    "Once the model is downloaded and installed, we can load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuuFgOdRRWif"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDZS9UkeY3Td"
   },
   "source": [
    "## Linguistic annotations\n",
    "\n",
    "spaCy's linguistic annotation types:\n",
    "\n",
    "*   Word types\n",
    "*   Parts of speech\n",
    "*   How words are related to each other\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-H7rJT8WNrg"
   },
   "source": [
    "### Word and sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nuob2h_df3mp"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNGRET97Wj9R"
   },
   "outputs": [],
   "source": [
    "text_sentence_1 = \"This is a class about text processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MX8sFJkkW1OJ",
    "outputId": "5231e5c0-db5f-4797-bec8-f161eecbb316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We pass the sentence to the doc\n",
    "doc1 = nlp(text_sentence_1)\n",
    "type(doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BX67YuReZgbC"
   },
   "source": [
    "[What is a **Doc**?](https://spacy.io/api/doc) It is a sequence of Token objects. Access sentences and named entities, export annotations to numpy arrays, losslessly serialize to compressed binary strings.\n",
    "\n",
    "And [what is a **Token**?](https://spacy.io/api/token) It is a word, punctuation symbol, whitespace, etcetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "aLRjNrFIX87p",
    "outputId": "ded66c0b-ec86-4cb9-d73d-bb01dec9d2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "class\n",
      "about\n",
      "text\n",
      "processing\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Let's tokenize th sentence\n",
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iHZ3mJkDbsHk",
    "outputId": "2eda94ce-1c1d-4cd6-91e8-1bba2433cd0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kCs2uD4ubz7h",
    "outputId": "62a77f44-2ce8-4cd3-f9ed-84bd80c2cf66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwZLWEsWaill"
   },
   "source": [
    "#### Linguistic features/annotation\n",
    "spaCy does not only have a record the position as if we will be splitting the sentence. spaCy records the grammatical structure of the sentence. \n",
    "\n",
    "So after tokenization (splitting the sentence into the individual components), spaCy can do **Part-of-speech** (POS) tagging. This is done by using spaCy's statistical models to make predictions of what each token is. For instance, a word following \"the\" in the English is most likely a noun. And that's why we need language models.\n",
    "\n",
    "---\n",
    "\n",
    "We have the following features that we can get per token:\n",
    "\n",
    "*   **Text**: The original word text.\n",
    "*   **Lemma**: The base form of the word.\n",
    "*   **POS**: The simple part-of-speech tag.\n",
    "*   **Tag**: The detailed part-of-speech tag.\n",
    "*   **Dep**: Syntactic dependency, i.e. the relation between tokens.\n",
    "*   **Shape**: The word shape – capitalization, punctuation, digits.\n",
    "*   **is alpha**: Is the token an alpha character?\n",
    "*   **is stop**: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "jfW-ItssX_V3",
    "outputId": "f7dcc408-3086-4905-80dc-9cbf6302e346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "coffee NOUN nsubj\n",
      "this DET det\n",
      "morning NOUN npadvmod\n",
      "costed VERB ccomp\n",
      "me PRON dative\n",
      "$ SYM nmod\n",
      "4 NUM dobj\n",
      ", PUNCT punct\n",
      "that PRON nsubj\n",
      "is AUX ROOT\n",
      "extremely ADV advmod\n",
      "expensive ADJ acomp\n",
      "! PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "text_sentence_2 = \"The coffee this morning costed me $4, that is extremely expensive!\"\n",
    "doc2 = nlp(text_sentence_2)\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "4wRjlK2uh4pL",
    "outputId": "44061668-b43e-4d0d-b1c1-4a579a9499c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>ALPHA</th>\n",
       "      <th>STOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>costed</td>\n",
       "      <td>cost</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>me</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>dative</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>$</td>\n",
       "      <td>nmod</td>\n",
       "      <td>$</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>dobj</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WDT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>extremely</td>\n",
       "      <td>extremely</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>expensive</td>\n",
       "      <td>expensive</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>acomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEXT      LEMMA    POS  TAG       DEP SHAPE  ALPHA   STOP\n",
       "0         The        the    DET   DT       det   Xxx   True   True\n",
       "1      coffee     coffee   NOUN   NN     nsubj  xxxx   True  False\n",
       "2        this       this    DET   DT       det  xxxx   True   True\n",
       "3     morning    morning   NOUN   NN  npadvmod  xxxx   True  False\n",
       "4      costed       cost   VERB  VBD     ccomp  xxxx   True  False\n",
       "5          me     -PRON-   PRON  PRP    dative    xx   True   True\n",
       "6           $          $    SYM    $      nmod     $  False  False\n",
       "7           4          4    NUM   CD      dobj     d  False  False\n",
       "8           ,          ,  PUNCT    ,     punct     ,  False  False\n",
       "9        that       that   PRON  WDT     nsubj  xxxx   True   True\n",
       "10         is         be    AUX  VBZ      ROOT    xx   True   True\n",
       "11  extremely  extremely    ADV   RB    advmod  xxxx   True  False\n",
       "12  expensive  expensive    ADJ   JJ     acomp  xxxx   True  False\n",
       "13          !          !  PUNCT    .     punct     !  False  False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can build a Pandas Dataframe with the contents of a token/doc loop, just for nice visualization\n",
    "import pandas as pd\n",
    "\n",
    "d = []\n",
    "for token in doc2:\n",
    "    d.append({'TEXT': token.text, 'LEMMA': token.lemma_, \n",
    "              'POS': token.pos_, 'TAG': token.tag_,\n",
    "              'DEP': token.dep_, 'SHAPE': token.shape_,\n",
    "              'ALPHA': token.is_alpha, 'STOP': token.is_stop})\n",
    "\n",
    "spacy_dataframe = pd.DataFrame(d)\n",
    "spacy_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUrOgHNmelLB"
   },
   "source": [
    "#### Do not feel lost! Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mlStXKJZenzG",
    "outputId": "e5591c6c-39b9-4d71-fb4d-b175290b24aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, 3rd person singular present'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use spacy.explain when lost\n",
    "spacy.explain(\"VBZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JkIRfHLbkaF8",
    "outputId": "eea764d4-ad04-4461-8e9d-dd1c3cb6e7d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverbial modifier'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"advmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "id": "fyxDoHVFkdV2",
    "outputId": "ae0d9f19-5e6c-400a-afd6-b6832c069bbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e03f2ed3d61c4d17a21c1787e8e5cb48-0\" class=\"displacy\" width=\"1250\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">coffee</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">morning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">costed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">me</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">4,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">extremely</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">expensive!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-0\" stroke-width=\"2px\" d=\"M70,202.0 C70,152.0 135.0,152.0 135.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,204.0 L62,192.0 78,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-1\" stroke-width=\"2px\" d=\"M170,202.0 C170,52.0 445.0,52.0 445.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,204.0 L162,192.0 178,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-2\" stroke-width=\"2px\" d=\"M270,202.0 C270,152.0 335.0,152.0 335.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,204.0 L262,192.0 278,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-3\" stroke-width=\"2px\" d=\"M370,202.0 C370,152.0 435.0,152.0 435.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,204.0 L362,192.0 378,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-4\" stroke-width=\"2px\" d=\"M470,202.0 C470,2.0 950.0,2.0 950.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,204.0 L462,192.0 478,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-5\" stroke-width=\"2px\" d=\"M470,202.0 C470,152.0 535.0,152.0 535.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M535.0,204.0 L543.0,192.0 527.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-6\" stroke-width=\"2px\" d=\"M670,202.0 C670,152.0 735.0,152.0 735.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,204.0 L662,192.0 678,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-7\" stroke-width=\"2px\" d=\"M470,202.0 C470,52.0 745.0,52.0 745.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,204.0 L753.0,192.0 737.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-8\" stroke-width=\"2px\" d=\"M870,202.0 C870,152.0 935.0,152.0 935.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,204.0 L862,192.0 878,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-9\" stroke-width=\"2px\" d=\"M1070,202.0 C1070,152.0 1135.0,152.0 1135.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1070,204.0 L1062,192.0 1078,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-10\" stroke-width=\"2px\" d=\"M970,202.0 C970,102.0 1140.0,102.0 1140.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e03f2ed3d61c4d17a21c1787e8e5cb48-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1140.0,204.0 L1148.0,192.0 1132.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Show POS and synthatic dependencies\n",
    "displacy.render(doc2, style=\"dep\", jupyter=True, options={'distance': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Nun7w-ErksfY",
    "outputId": "d25b22a4-c880-4424-ef36-f26bd5c49f83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The coffee \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    this morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " costed me $\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ", that is extremely expensive!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The entity visualizer highlights named entities and their labels in the text\n",
    "displacy.render(doc2, style=\"ent\", jupyter=True, options={'distance': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zXsGHrIqadY"
   },
   "source": [
    "#### Tokenization rules\n",
    "\n",
    "The tokenization applies rules specific to each language. For instance, punctuation at the end of a sentence should be split off – whereas “U.K.” should remain one token. Also don't should be split as **do** and **not** and such.\n",
    "\n",
    "Those form part of the tokenizer exceptions, that make all that decisions for each language model on whether to split a word or not.\n",
    "\n",
    "* **Tokenizer exception**: Special-case rule to split a string into several tokens or prevent a token from being split when punctuation rules are applied.\n",
    "* **Prefix**: Character(s) at the beginning, e.g. $, (, “, ¿.\n",
    "* **Suffix**: Character(s) at the end, e.g. km, ), ”, !.\n",
    "* **Infix**: Character(s) in between, e.g. -, --, /, ….\n",
    "\n",
    "If we want to change the tokenization or add some, we will need to create our own rules (rarely used unless you are dealing with scientific/slang languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DS48FrWKskO3"
   },
   "outputs": [],
   "source": [
    "text_sentence_3 = \"I was accepted at UCL-CV Master in U.K., but I didn't have enough money for it!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "BLSJVLMerHhf",
    "outputId": "262e4422-80ba-49eb-8817-abd1ef0c99f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'was',\n",
       " 'accepted',\n",
       " 'at',\n",
       " 'UCL-CV',\n",
       " 'Master',\n",
       " 'in',\n",
       " 'U.K.,',\n",
       " 'but',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'have',\n",
       " 'enough',\n",
       " 'money',\n",
       " 'for',\n",
       " 'it!']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "With Python we can also split the text using .split().\n",
    "\n",
    "The problem is that we do not retain contextual token information.\n",
    "Such as do/not or punctuations such as commas or exclamations.\n",
    "\"\"\"\n",
    "\n",
    "text_sentence_3.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "er1OCTJSlz4u",
    "outputId": "9acb4b19-feb0-4f21-a14e-9752651f94f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "was\n",
      "accepted\n",
      "at\n",
      "UCL\n",
      "-\n",
      "CV\n",
      "Master\n",
      "in\n",
      "U.K.\n",
      ",\n",
      "but\n",
      "I\n",
      "did\n",
      "n't\n",
      "have\n",
      "enough\n",
      "money\n",
      "for\n",
      "it\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(text_sentence_3)\n",
    "\n",
    "for token in doc3:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsidWPPVvgvu"
   },
   "source": [
    "##### Creating our own rule\n",
    "\n",
    "Global and language-specific tokenizer data is supplied via the language data in spacy/lang. The tokenizer exceptions define special cases like “don’t” in English, which needs to be split into two tokens: {ORTH: \"do\"} and {ORTH: \"n't\", NORM: \"not\"}. The prefixes, suffixes and infixes mostly define punctuation rules – for example, when to split off periods (at the end of a sentence), and when to leave tokens containing periods intact (abbreviations like “U.S.”).\n",
    "\n",
    "![alt text](https://spacy.io/language_data-ef63e6a58b7ec47c073fb59857a76e5f.svg)\n",
    "\n",
    "Anything that’s specific to a domain or text type – like financial trading abbreviations, or Bavarian youth slang – should be added as a special case rule to your tokenizer instance. If you’re dealing with a lot of customizations, it might make sense to create an entirely custom subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "XspIC2OirfGu",
    "outputId": "ebc77be8-6c17-4fd8-8bfc-f1bf6cce8569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      ",\n",
      "gim\n",
      "me\n",
      "your\n",
      "money\n"
     ]
    }
   ],
   "source": [
    "text_sentence_4 = \"Hey, gimme your money\" \n",
    "\n",
    "doc4 = nlp(text_sentence_4)\n",
    "\n",
    "for token in doc4:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttqRCuuQw6On"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "text_sentence_4 = \"Hey, gimme your money\" \n",
    "doc4 = nlp(text_sentence_4)\n",
    "\n",
    "# Add special case rule\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "NspnM88txUDc",
    "outputId": "84d3a699-b76d-4a1f-da9d-02c9ef3d059e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      ",\n",
      "gim\n",
      "me\n",
      "your\n",
      "money\n"
     ]
    }
   ],
   "source": [
    "text_sentence_4 = \"Hey, gimme your money\" \n",
    "\n",
    "doc4 = nlp(text_sentence_4)\n",
    "\n",
    "for token in doc4:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQwVTWHQztz8"
   },
   "source": [
    "##### Long sentences and weird spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "mYIaQp2k45gd",
    "outputId": "c45cc958-28c8-4788-baa8-f9f032813e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some\n",
      "\n",
      "\n",
      "spaces\n",
      " \n",
      "and\n",
      "\t\n",
      "tab\n",
      "characters\n"
     ]
    }
   ],
   "source": [
    "text_sentence_5 = 'Some\\nspaces  and\\ttab characters'\n",
    "\n",
    "doc5 = nlp(text_sentence_5)\n",
    "\n",
    "for token in doc5:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NVkzoQAw5FsY",
    "outputId": "5cc648e9-d0eb-4e2b-be0f-23cabbec6aa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[1].is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "UEvV03B05KdP",
    "outputId": "2e6fe058-d195-4053-8e89-27ffb956832d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ancient Rome, some neighbors live in three adjacent houses.\n",
      "In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus.\n",
      "A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom.\n",
      "One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates).\n",
      "One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero.\n",
      "Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\n"
     ]
    }
   ],
   "source": [
    "text_sentence_6 = \"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\n",
    "\n",
    "doc6 = nlp(text_sentence_6)\n",
    "\n",
    "for sent in doc6.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1H-VPRB6W7l"
   },
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is the assignation of the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E19GCEnZ6P9v",
    "outputId": "fd62330c-2d82-4315-da08-c43bf743a07d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neighbour'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"they are neighbours\")[-1].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BVD7TNvv639P",
    "outputId": "e817ea6f-2840-4dd9-c818-d9e72a5b006d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZIHap1F26_bH",
    "outputId": "01f4191a-ecb8-479d-8e42-05db723263b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "orAIfks77Hk_",
    "outputId": "bc9647c9-ce9f-4bad-f08a-695bb464d651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f8556ed2558>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting information about a token\n",
    "doc6.vocab['is']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdjoTxuG7s_V"
   },
   "source": [
    "#### Dealing with STOP words\n",
    "In computing, stop words are words which are filtered out before processing of natural language data (text). Stop words are generally the most common words in a language; there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list. Some tools avoid removing stop words to support phrase search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KJjuIZla7Lqf",
    "outputId": "3f678fd5-f642-4785-a8d7-e6ae7e9e42f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', 'many', 'side', 'further', 'n’t', '’s', '‘d', 'anyone', 'by', 'fifteen', 'what', 'take', 'through', 'thus', 'too', 'least', 'whether', 'whereupon', '‘re', 'although', 'quite', 'both', 'does', 'hereafter', 'those', 'again', 'third', 'which', 'top', 'always', 'over', 'hereby', 'anywhere', 'only', 'next', 'doing', 'so', 'you', 'make', 'their', 'together', 'eleven', 'along', 'why', 'made', 'toward', 'had', 'once', 'has', 'call', 'seems', 'thru', 'unless', 're', 'have', 'move', 'nine', 'full', 'wherever', 'noone', 'after', 'everyone', 'show', 'them', 'and', 'whence', \"'d\", 'any', 'fifty', 'either', 'really', 'three', 'are', 'throughout', 'all', '’d', 'whither', 'below', 'behind', 'its', 'my', 'own', 'between', 'forty', 'thence', 'they', 'becoming', 'under', 'me', 'sometimes', 'an', 'into', 'empty', 'thereupon', 'used', 'last', 'across', 'well', 'hundred', 'must', 'former', 'besides', 'something', 'whose', 'name', 'or', 'anyhow', 'eight', 'see', '‘ll', 'ten', 'during', 'hers', 'in', 'your', 'though', 'he', 'indeed', 'ever', 'seem', 'for', 'that', '’m', 'however', 'amount', 'yours', 'still', 'against', 'is', 'beforehand', 'may', 'off', 'sixty', 'himself', 'ours', \"'s\", 'nobody', '’ll', 'to', 'being', 'namely', 'hereupon', 'two', 'every', 'whereas', 'often', 'more', 'per', 'somewhere', 'several', 'him', 'neither', 'whoever', 'how', 'using', 'even', 'everything', 'less', 'n‘t', 'moreover', 'already', 'everywhere', 'seeming', 'this', 'afterwards', 'becomes', 'our', '‘s', 'herself', 'serious', 'whole', 'enough', 'here', 'where', 'due', 'mostly', 'twelve', 'i', 'via', 'of', 'another', 'am', 'other', 'up', 'ca', '’re', 'be', 'can', 'nowhere', 'these', 'yourselves', '‘ve', 'upon', 'became', 'almost', 'hence', 'never', 'from', 'somehow', 'just', 'above', 'around', 'bottom', 'nor', 'back', 'one', 'should', 'whatever', 'regarding', 'whereafter', 'yet', 'did', 'no', 'been', 'each', 'anything', 'done', 'itself', 'cannot', 'if', 'five', 'keep', 'latter', 'she', 'also', 'sometime', 'twenty', \"'re\", 'anyway', 'front', 'formerly', 'down', 'seemed', 'because', 'elsewhere', 'nothing', 'such', 'ourselves', 'therefore', 'wherein', 'it', 'nevertheless', 'put', 'as', 'go', 'rather', 'become', 'the', 'beyond', 'out', 'few', 'thereby', 'very', 'when', 'alone', 'mine', 'yourself', \"'ll\", \"n't\", 'were', 'please', 'but', 'herein', 'get', 'part', 'six', 'therein', 'than', 'towards', 'whom', 'whereby', 'within', 'then', 'meanwhile', 'same', 'myself', 'none', 'while', 'do', 'with', 'much', 'until', 'now', 'without', 'would', \"'ve\", 'was', 'at', 'before', 'give', 'not', \"'m\", '‘m', 'onto', 'perhaps', 'say', 'else', 'there', 'his', 'thereafter', 'we', '’ve', 'us', 'first', 'since', 'some', 'about', 'beside', 'could', 'four', 'her', 'will', 'someone', 'most', 'themselves', 'others', 'otherwise', 'except', 'might', 'among', 'on', 'various', 'who', 'amongst', 'latterly', 'whenever'}\n"
     ]
    }
   ],
   "source": [
    "# Getting STOP words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h6KuLWRV72_X",
    "outputId": "c8342ed2-89d8-4054-bfad-962087f4b4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In --> is stopword? --> False\n"
     ]
    }
   ],
   "source": [
    "print(doc6[0], \"--> is stopword? -->\", doc6[0] in STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ze9L3mcL97nm"
   },
   "source": [
    "\"In\" is not found in the list of common words, however spaCy changes automatically to lower case to find that actually \"In\" is \"in\" and therefore is a stopword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XiSaZtvq8Dun",
    "outputId": "1ee47721-1f92-4b71-9796-2d9298206cc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6[0].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjJ5na1b-O92"
   },
   "source": [
    "### In class exercise:\n",
    "\n",
    "Display a table with all the tokens of `text1` and the columns `[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"]`. Look in https://spacy.io/api/token#attributes for hints. Something like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Text</th>\n",
    "      <th>Lemma</th>\n",
    "      <th>Coarse POS (pos)</th>\n",
    "      <th>Fine POS (tag)</th>\n",
    "      <th>Syntactic dependency</th>\n",
    "      <th>Shape</th>\n",
    "      <th>Alphanumeric</th>\n",
    "      <th>Stop</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>This</td>\n",
    "      <td>this</td>\n",
    "      <td>DET</td>\n",
    "      <td>DT</td>\n",
    "      <td>nsubj</td>\n",
    "      <td>Xxxx</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>is</td>\n",
    "      <td>be</td>\n",
    "      <td>VERB</td>\n",
    "      <td>VBZ</td>\n",
    "      <td>ROOT</td>\n",
    "      <td>xx</td>\n",
    "      <td>True</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Also, create a dependency and entity graph of the sentence.\n",
    "\n",
    "Use the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-AIgn__-leF"
   },
   "outputs": [],
   "source": [
    "exercise_sentece = \"This is great! We are learning text processing with spaCy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkru_Zpi5yhO"
   },
   "source": [
    "## spaCy pipelines\n",
    "\n",
    "When we call `nlp` on a text, spaCy tokenizes the ext to produce a `Doc`. The processing pipeline has different steps that are removed from the complexity of the user but that [can be tweaked if needed](https://spacy.io/usage/processing-pipelines).\n",
    "\n",
    "![alt text](https://spacy.io/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3WXfgOF-wYg"
   },
   "source": [
    "## Entity recognition\n",
    "\n",
    "A **named entity** is a *real-world object* that’s assigned a name – for example, a person, a country, a product or a book title.\n",
    "\n",
    "spaCy can recognize [many types of named entities](https://spacy.io/api/annotation#named-entities), by predicting over a language model. Results are not 100% accurate as models are statistical and depends on the examples they are trained on, but this can be fine tuned for you later on.\n",
    "\n",
    "Named entities can be accessed from the *ents* properties of a spaCy *Doc*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bwX_KZWP29D"
   },
   "outputs": [],
   "source": [
    "text_sentence_7 = u'Apple is looking at buying U.K. startup for 1 billion USD'\n",
    "doc7 = nlp(text_sentence_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqzU-QnArT9E"
   },
   "source": [
    "There are certain entity properties that can be accessed:\n",
    "\n",
    "* **Text**: The original entity text.\n",
    "* **Start**: Index of start of entity in the Doc.\n",
    "* **End**: Index of end of entity in the Doc.\n",
    "* **Label**: Entity label, i.e. type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jpeSXMhhP29H",
    "outputId": "bfd2cf15-a3e4-4625-96c7-14ef6d7cc2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "1 billion USD 44 57 MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc7.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "M-kt6zFtP29K",
    "outputId": "0b289a0a-0d78-473a-8d9e-a1b191f5a3a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " USD</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc7, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "LBS2-ke3-vLv",
    "outputId": "0cce6fd3-d984-472c-990e-ab19ba194974"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Rome\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", some neighbors live in \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " adjacent houses. In the center is the house of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", who lives there with wife \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", son \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and several slaves, including head slave Hysterium and the musical's main character \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". A slave belonging to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " wishes to buy, win, or steal his freedom. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the neighboring houses is owned by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Marcus Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is a buyer and seller of beautiful women; the other belongs to the ancient \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Erronius\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is abroad searching for his long-lost children (stolen in infancy by pirates). \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One day\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " go on a trip and leave \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in charge of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". Hero confides in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " that he is in love with the lovely \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Philia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", one of the courtesans in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the House of Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (albeit still a virgin).</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc6, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTx01agLvxGi"
   },
   "source": [
    "## Word vectors and similarity\n",
    "\n",
    "The similarity or distance between two words can be done by comparing **word vectors** or *word embeddings*, which are multi-dimensional meaning representations of a word.\n",
    "\n",
    "Word vectors are usually created by using an algorithm like word2vec.\n",
    "\n",
    "To make them compact and fast, spaCy’s small models (all packages that end in sm) don’t ship with word vectors, and only include context-sensitive tensors. This means you can still use the similarity() methods to compare documents, spans and tokens – but the result won’t be as good, and individual tokens won’t have any vectors assigned. So in order to use real word vectors, you need to download a larger model, such as `en_core_web_md` or `en_core_web_lg`.\n",
    "\n",
    "**IMPORTANT!!** In Google Colab, download the following cell and then restart runtime to locate the downloaded model.\n",
    "\n",
    "A word vector looks like the following array: \n",
    "\n",
    "![alt text](https://miro.medium.com/max/560/1*Bp64BP0Buo9ZZWIyh6QzEQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "f2lQoQpowKC-",
    "outputId": "474f3ad2-c11f-49d2-8906-bb1f3f928640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz#egg=en_core_web_md==2.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from en_core_web_md==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (1.17.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.2.2)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (1.25.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/marcelo-landivar/anaconda3/envs/bts36/lib/python3.6/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_md==2.2.0) (4.36.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWqmnIZa0yzy"
   },
   "source": [
    "The word vectors can be explored with the following techniques then:\n",
    "\n",
    "* **Text**: The original token text.\n",
    "* **has vector**: Does the token have a vector representation?\n",
    "* **Vector norm**: The L2 norm of the token’s vector (the square root of the sum of the values squared)\n",
    "* **OOV**: Out-of-vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "fkPFASlR_iOI",
    "outputId": "b79bc861-dfe7-455c-f392-926960444c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QT-fbAZf2bfB"
   },
   "source": [
    "The words “dog”, “cat” and “banana” are all pretty common in English, so they’re part of the model’s vocabulary, and come with a vector. The word “afskfsd” on the other hand is a lot less common and out-of-vocabulary – so its vector representation consists of 300 dimensions of 0, which means it’s practically nonexistent. \n",
    "\n",
    "spaCy is able to compare two objects, and make a prediction of how similar they are. Predicting similarity is useful for building recommendation systems or flagging duplicates. For example, you can suggest a user content that’s similar to what they’re currently looking at, or label a support ticket as a duplicate if it’s very similar to an already existing one.\n",
    "\n",
    "Each Doc, Span and Token comes with a .similarity() method that lets you compare it with another object, and determine the similarity. Of course similarity is always subjective – whether “dog” and “cat” are similar really depends on how you’re looking at it. spaCy’s similarity model usually assumes a pretty general-purpose definition of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "QM55wLVeyra1",
    "outputId": "81da53a1-7856-4770-97df-1a31f147a614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.80168545\n",
      "dog banana 0.24327643\n",
      "cat dog 0.80168545\n",
      "cat cat 1.0\n",
      "cat banana 0.28154364\n",
      "banana dog 0.24327643\n",
      "banana cat 0.28154364\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")  # make sure to use larger model!\n",
    "tokens = nlp(\"dog cat banana\")\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PaCnvLAi6iGW"
   },
   "source": [
    "## The Vocab object\n",
    "\n",
    "spaCy tries to store the data in a vocabulary, i.e. `Vocab` that is shared by multiple documents. \n",
    "\n",
    "To save memory, spaCy also encodes all strings to hash values – in this case for example, “coffee” has the hash 3197928453018144401. Entity labels like “ORG” and part-of-speech tags like “VERB” are also encoded. Internally, spaCy only “speaks” in hash values.\n",
    "\n",
    "* **Token**: A word, punctuation mark etc. in context, including its attributes, tags and dependencies.\n",
    "* **Lexeme**: A “word type” with no context. Includes the word shape and flags, e.g. if it’s lowercase, a digit or punctuation.\n",
    "* **Doc**: A processed container of tokens in context.\n",
    "* **Vocab**: The collection of lexemes.\n",
    "* **StringStore**: The dictionary mapping hash values to strings, for example 3197928453018144401 → “coffee”.\n",
    "\n",
    "Thus: \n",
    "\n",
    "* `Vocab` objects contain a set of look-up tables that make common information available across documents.\n",
    "* Indexing the `Vocab` retrieves a `Lexeme`, which contains all the context-independent information about a word.\n",
    "\n",
    "![alt text](https://spacy.io/vocab_stringstore-1d1c9ccd7a1cf4d168bfe4ca791e6eed.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qj-5mite9mIK",
    "outputId": "6e103ca2-39a5-4f59-be0b-8f483c8e2c8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x7fe24db15848>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vg-Q-_XV9sqm",
    "outputId": "59bfdc59-2db5-4929-a615-694204815ec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7fe22eae7288>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc7.vocab[\"Apple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vjCFRsyo94G1",
    "outputId": "a7def412-7c4d-4a82-9b98-bc8794d7e6a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7fe22eae7e58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex = doc7.vocab[\"million\"]\n",
    "lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dixcACbB994o",
    "outputId": "ffbbb94e-10a1-461d-a66b-e27567f509fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxxx'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.shape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-1I3Kp_V-AzH",
    "outputId": "c65ab9d6-c5d9-49cf-c78d-16fcd1979118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'million'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T6gbPjeh-B_j",
    "outputId": "addbcaeb-bae4-42ce-f58c-e451840d7360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.is_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgVUba0w6x-c"
   },
   "source": [
    "# Hands on: practical examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQJAS9b67KIB"
   },
   "source": [
    "## Word frequency\n",
    "\n",
    "We can compute the word frequency on a text using spaCy. Within the Holy Grail dataset, lets:\n",
    "\n",
    "\n",
    "\n",
    "*   Let's find the 5 most common nouns\n",
    "*   Let's find the 20 most common lemmas that are not stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5ltWhKMGdbM"
   },
   "source": [
    "### Find the 5 most common nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "uZ3zlWUS602k",
    "outputId": "8f824c4a-6df8-478e-c46e-28def711db38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-13 16:12:00--  https://raw.githubusercontent.com/vfp1/bts-mbds-data-science-foundations-2019/master/sessions/data/holy_grail.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 65003 (63K) [text/plain]\n",
      "Saving to: ‘holy_grail.txt.3’\n",
      "\n",
      "holy_grail.txt.3    100%[===================>]  63.48K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2019-11-13 16:12:01 (1.10 MB/s) - ‘holy_grail.txt.3’ saved [65003/65003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/vfp1/bts-mbds-data-science-foundations-2019/master/sessions/data/holy_grail.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8ETiMYyBkqo"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "holy_grail = nlp(open('holy_grail.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMsQCxazDBe-"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "char_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'NOUN' and token.text not in STOP_WORDS and token.text != '#':\n",
    "        char_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2ryIDsxuDONW",
    "outputId": "4ddf760b-8969-4c37-8f0c-2423f1eb4985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 42), ('witch', 37), ('music', 29), ('clop', 26), ('singing', 26)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdz3FWI9Gi79"
   },
   "source": [
    "### Find the 20 most common lemmas that are not stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIXHe3iCGxMx"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "lemmas = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if not token.is_punct and not token.is_space and token.lower_ and token.like_num not in STOP_WORDS:\n",
    "        lemmas[token.lemma_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "yAn8t5kKHRMB",
    "outputId": "241e965a-0082-4eab-d45d-081f6634bb24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-PRON-', 1238),\n",
       " ('be', 482),\n",
       " ('the', 332),\n",
       " ('a', 233),\n",
       " ('ARTHUR', 225),\n",
       " ('and', 184),\n",
       " ('of', 176),\n",
       " ('not', 162),\n",
       " ('to', 152),\n",
       " ('no', 129),\n",
       " ('do', 119),\n",
       " ('oh', 110),\n",
       " ('have', 108),\n",
       " ('that', 104),\n",
       " ('in', 97),\n",
       " ('what', 92),\n",
       " ('1', 76),\n",
       " ('LAUNCELOT', 76),\n",
       " ('well', 68),\n",
       " ('KNIGHT', 66)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(lemmas)\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRRSwVjpJXxF"
   },
   "source": [
    "### Your turn\n",
    "\n",
    "* Let's find the 5 most common verbs\n",
    "* Let's find the 5 most common personal names\n",
    "* Let's find the 20 most common lemmas that are not stopwords, not numbers and not personal names\n",
    "* What happens? Why some strange character appears? Next session we will learn how to filter through those to create cool t-SNE graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "stop = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if not token.pos_ == 'PROPN' and not token.is_punct and token.lower_ and not token.is_space and not token.is_digit not in STOP_WORDS:\n",
    "        stop[token.lemma_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(stop)\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "char_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'VERB':\n",
    "        char_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Burn', 32), ('got', 27), ('Come', 26), ('tell', 24), ('Look', 24)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "name_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        name_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('LAUNCELOT', 76),\n",
       " ('KNIGHT', 66),\n",
       " ('GALAHAD', 64),\n",
       " ('FATHER', 62)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_xXkO_b7WrG"
   },
   "source": [
    "## Dispersion plots\n",
    "\n",
    "1. Load the `holy_grail.txt` dataset and create a dictionary of names and indexes like `{\"NAME\": [1, 2, 5, 10, ...]}` to store when does each proper noun appear among the 5 most frequent ones.\n",
    "2. Visualize the appearances of the character that is named the most.\n",
    "3. Visualize in the same graph the appearances of the top 5 characters to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jma_xH1s7YD0"
   },
   "outputs": [],
   "source": [
    "from spacy import load\n",
    "\n",
    "nlp = load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lY3hpd3VIIDb"
   },
   "outputs": [],
   "source": [
    "holy_grail = nlp(open(\"holy_grail.txt\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcUhtPg3KMYa"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "char_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        char_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FQLta8KLKQhc",
    "outputId": "fd4b2cf1-b7d1-4a12-c78b-f58456e739c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('LAUNCELOT', 76),\n",
       " ('KNIGHT', 66),\n",
       " ('GALAHAD', 64),\n",
       " ('FATHER', 62)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZSZrhV_ML2C"
   },
   "source": [
    "We get Sir or HEAD within the characters, actually HEAD is a character, but Sir is not, let's change that using a `special case`, instead of the longer and ardous task of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Mpqv-9tMeUu"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.symbols import ORTH, POS, NOUN, VERB, TAG\n",
    "\n",
    "nlp_modified = spacy.load('en')\n",
    "nlp_modified.tokenizer.add_special_case('Sir', [{ORTH: 'Sir', POS: NOUN, TAG: NOUN}])\n",
    "nlp_modified.tokenizer.add_special_case('Grail', [{ORTH: 'Grail', POS: NOUN, TAG: NOUN}])\n",
    "nlp_modified.tokenizer.add_special_case('BLACK', [{ORTH: 'BLACK', POS: NOUN, TAG: NOUN}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjikAIe0Mtmy"
   },
   "source": [
    "Let's try it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eu6fFJRM9nB"
   },
   "outputs": [],
   "source": [
    "holy_grail2 = nlp_modified(open(\"holy_grail.txt\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCaMiq2lMxUm"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "char_counter2 = Counter()\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        char_counter2[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ERH8zzWgMzI6",
    "outputId": "529e3243-f456-452c-e5a9-da852d8809e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('LAUNCELOT', 76),\n",
       " ('KNIGHT', 66),\n",
       " ('GALAHAD', 64),\n",
       " ('FATHER', 62)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter2.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDL1Cl_wRpMB"
   },
   "source": [
    "### Visualize the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lH8gjzkYRtOp",
    "outputId": "7df94ade-0911-4dc9-8639-ccf76ef43476"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter2.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ceu5EvnKQ5-"
   },
   "outputs": [],
   "source": [
    "names, _ = zip(*char_counter2.most_common(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IS94mXKWPh0t"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xAu-X9I1RHLt"
   },
   "outputs": [],
   "source": [
    "indexes = defaultdict(list)\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.text in names:\n",
    "        indexes[token.text].append(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Ie9U4y2uRKa2",
    "outputId": "600fe371-be30-473f-9142-62a9cd32f2ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe24b6d1198>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.eventplot(indexes[name], label=name)\n",
    "axes.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0WqqmIiTHoY"
   },
   "source": [
    "### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oNCam-CtTlAW",
    "outputId": "4160b653-7f24-4284-88b4-609432e503ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('LAUNCELOT', 76),\n",
       " ('KNIGHT', 66),\n",
       " ('GALAHAD', 64),\n",
       " ('FATHER', 62)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter2.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv63xSimTlAb"
   },
   "outputs": [],
   "source": [
    "names, _ = zip(*char_counter2.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekEirwPqTlAe"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_WuRbgYTlAg"
   },
   "outputs": [],
   "source": [
    "indexes = defaultdict(list)\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.text in names:\n",
    "        indexes[token.text].append(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "yKL5yFmKTlAj",
    "outputId": "f2576bc2-d2e0-480f-8b72-9edff5af8a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe24b87ffd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True)\n",
    "\n",
    "for ii, name in enumerate(names):\n",
    "    axes[ii].eventplot(indexes[name], label=name, color=\"C{}\".format(ii))\n",
    "    axes[ii].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_counter_ex1 = Counter()\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.pos == 'NOUN':\n",
    "        indexes[token.text]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter_ex1.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.text != '#'and token.text != Sir in names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJTnDhDzUnAx"
   },
   "source": [
    "## Your turn:\n",
    "\n",
    "* Try to plot the NOUNS and clean the Doc whenever necessary adding special cases\n",
    "\n",
    "* Try the same exercise with [this file in the GitHub repo](https://github.com/vfp1/bts-mbds-data-science-foundations-2019/raw/master/sessions/data/pride_and_prejudice.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi1SIWOoU81W",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-05 08:57:23--  https://raw.githubusercontent.com/vfp1/bts-mbds-data-science-foundations-2019/master/sessions/data/pride_and_prejudice.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.128.133, 151.101.64.133, 151.101.0.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.128.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 704145 (688K) [text/plain]\n",
      "Saving to: ‘pride_and_prejudice.txt.1’\n",
      "\n",
      "pride_and_prejudice 100%[===================>] 687.64K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-11-05 08:57:24 (5.17 MB/s) - ‘pride_and_prejudice.txt.1’ saved [704145/704145]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/vfp1/bts-mbds-data-science-foundations-2019/master/sessions/data/pride_and_prejudice.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "holy_grail = nlp(open('pride_and_prejudice.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2QHBivImfOvp",
    "uUrOgHNmelLB",
    "ZjJ5na1b-O92"
   ],
   "name": "08_Text_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
