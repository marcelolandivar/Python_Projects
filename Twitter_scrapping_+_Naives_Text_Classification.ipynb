{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Twitter_scrapping + Naives_Text_Classification",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelolandivar/Python_Projects/blob/master/Twitter_scrapping_%2B_Naives_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-dV9T_BoeCx",
        "colab_type": "text"
      },
      "source": [
        "# TWITTER SCRAPPING AND TEXT CLASSIFICATION WITH NAIVES BAYES\n",
        "###By: Marcelo Landivar\n",
        "\n",
        "*  The current notebook is a test for scrapping tweets from different accounts and provides different features to extract more specific tweets.\n",
        "*  The model classifies the tweets to different topic lavbels using a Simplify Naives Bayes Model trained using 20news dataset.\n",
        "*  The final result is a table with the tweet and the corresponding label. The output can also be a CSV file.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        ">**Email:** <MarceloLandivar24@gmail.com>\\\n",
        "> **RESOURCES:**  Sklearn, GetOldTweets\n",
        "\n",
        "\n",
        "Open this notebook in Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HI3QOn60OF3IQDrDsW3SmjiB-ErHNTT9?usp=sharing)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poa_3KqVoeCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2322175d-58b8-4e80-b1e0-492baa0e7970"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AokAFm8gqjql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "471adf83-f112-4954-ac28-709386724ff7"
      },
      "source": [
        "\"\"\"Install GetOldTweets library:\n",
        "   Exports tweets to a specified csv file (\"output_got.csv\" by default).\"\"\"\n",
        "!pip install GetOldTweets3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Install GetOldTweets library:\\n   Exports tweets to a specified csv file (\"output_got.csv\" by default).'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting GetOldTweets3\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
            "Collecting pyquery>=1.2.10\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
            "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex-Pteg7oeC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the model to be able to draw tweets from Twitter\n",
        "import GetOldTweets3 as got\n",
        "\n",
        "class tweets:\n",
        "  \"\"\"\n",
        "  Scrapping tweets using GetOldTweets library. It is necessary to set the account name and the maximum number of tweets. Additionally, it is possible to \n",
        "  mention the dates from and to and bolean whether you want the top tweets. Also, all data from the tweets and user can be displayed.\n",
        "  \"\"\"\n",
        "  def __init__(self, account_name, max_tweets, date_from=None, date_to=None, top_tweets=False):\n",
        "    self.account_name = account_name\n",
        "    self.max_tweets = max_tweets\n",
        "    self.date_from= date_from\n",
        "    self.date_to = date_to\n",
        "    self.top_tweets= top_tweets\n",
        "    if (self.date_from==None) & (self.date_to==None):\n",
        "      self.tweet_config = got.manager.TweetCriteria().setUsername(self.account_name).setMaxTweets(self.max_tweets).setTopTweets(self.top_tweets)\n",
        "    else:\n",
        "      self.tweet_config = got.manager.TweetCriteria().setUsername(self.account_name).setMaxTweets(self.max_tweets).setSince(self.date_from).setUntil(self.date_to).setTopTweets(self.top_tweets)\n",
        "\n",
        "    \n",
        "  def print_tweets(self):\n",
        "    tweets_list = []\n",
        "    for i in range(self.max_tweets):\n",
        "      tweet = got.manager.TweetManager.getTweets(self.tweet_config)[i]\n",
        "      tweets_list.append(tweet.text)\n",
        "    return tweets_list\n",
        "\n",
        "  def tweets_data(self):\n",
        "    tweets_data_list = []\n",
        "    for i in range(self.max_tweets):\n",
        "      tweet=got.manager.TweetManager.getTweets(self.tweet_config)[i]\n",
        "      tweets_data_list.append([i,tweet.username, tweet.favorites, tweet.retweets, tweet.date])\n",
        "    return tweets_data_list\n",
        "\n",
        "  def tweets_topic(self, topic):\n",
        "    \"Add a label based on the user and tweets you have scrapped\"\n",
        "    self.topic = topic\n",
        "    tweets_list = []\n",
        "    for i in range(self.max_tweets):\n",
        "      tweet = got.manager.TweetManager.getTweets(self.tweet_config)[i]\n",
        "      tweets_list.append([tweet.text, topic])\n",
        "    return tweets_list\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyFunK_17YiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting tweets for two different categories: Baseball and Apple computers news\n",
        "\n",
        "jmc = tweets('jamiemclennan29', 25)\n",
        "tweets_jmc = jmc.print_tweets()\n",
        "tweets_data_jmc= jmc.tweets_data()\n",
        "\n",
        "mac = tweets('MacRumors', 25)\n",
        "tweets_mac = mac.print_tweets()\n",
        "tweets_data_mac = mac.tweets_data()\n",
        "\n",
        "xy = tweets('2010MisterChip', 2)\n",
        "xy_print = xy.print_tweets()"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFZYYHUWro1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ac0f6912-8f45-4ebb-bb6f-c7ae9d9a1dc8"
      },
      "source": [
        "# Visualizing one of the tweets and the data for the tweet\n",
        "tweets_data_mac[3], tweets_mac[3]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3,\n",
              "  'MacRumors',\n",
              "  38,\n",
              "  12,\n",
              "  datetime.datetime(2020, 8, 19, 9, 20, 24, tzinfo=datetime.timezone.utc)],\n",
              " 'Korean Startups Call for Investigation into Apple and Google In-App Purchases https://www.macrumors.com/2020/08/19/korea-call-for-investigation-into-apple-and-google/ by @hartleycharlton')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UwMTca009bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomize the extracted tweets\n",
        "def randomize_tweets(*tweets):\n",
        "  lista = []\n",
        "  for tweet in tweets:\n",
        "    for t in tweet:\n",
        "      lista.append(t)\n",
        "  tweets_list= random.sample(lista, len(lista)) \n",
        "  return tweets_list"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsWu1iLU94gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets= randomize_tweets(tweets_mac, tweets_jmc, xy_print)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5j7EsN5ukAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It is possible to use the original dataset of 20news or use a different a more complete dataset\n",
        "#!wget -c http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\n",
        "#!tar -zxvf /content/20news-18828.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8quiV2AsxZv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare Multinomial Bayes' classifier\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Fetech the 20news data, create the categories from the dataset and set the training dataset\n",
        "data = fetch_20newsgroups()\n",
        "categories = list(enumerate(data.target_names))\n",
        "train_dataset = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "#Create a model for classifiying the tweets\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "trained_model = model.fit(train_dataset.data, train_dataset.target)\n",
        "labels = trained_model.predict(tweets)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSl0xAUiusJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Provide the final prediction of the tweets and the chance to save the results in a csv in the current working folder\n",
        "def prediction_dataframe(labels, categories, csv=False):\n",
        "\n",
        "  def predict_category(labels, categories):\n",
        "    predictions = []\n",
        "    for a,b in categories:\n",
        "      for i in labels:\n",
        "        if i==a:\n",
        "          predictions.append(b)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "  prediction = predict_category(labels, categories)\n",
        "  result = pd.DataFrame(list(zip(tweets, prediction)), \n",
        "               columns =['Tweet', 'Prediction'])\n",
        "  if csv==True:\n",
        "    result.to_csv(\"Tweets_Topic_Classification.csv\", encoding='utf-8') \n",
        "  return result"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP6-Yp2F8RDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "8b96ccc8-b39e-4beb-a1c8-4bb7cf7557c5"
      },
      "source": [
        "# Table with the results\n",
        "result = prediction_dataframe(labels, categories)\n",
        "result[:3]"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apple Seeds Fifth Beta of tvOS 14 to Developer...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Epic Games Aiming to Recruit ‘Coalition of App...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apple Says ‘We Won’t Make an Exception’ for Ep...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet     Prediction\n",
              "0  Apple Seeds Fifth Beta of tvOS 14 to Developer...  comp.graphics\n",
              "1  Epic Games Aiming to Recruit ‘Coalition of App...  comp.graphics\n",
              "2  Apple Says ‘We Won’t Make an Exception’ for Ep...  comp.graphics"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeW_WLhzLRFR",
        "colab_type": "text"
      },
      "source": [
        "The model itself is straightforward and simple. It can be improved with a better and more complete dataset. The Naive Bayes Classifier is very interesting method and can be improved using n-gram probabilistic model. Or it is possible to go beyond that and use Recurrent Neural Networks (RNN) using big corpus of several tweets in a single text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRjBZniFMyUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}