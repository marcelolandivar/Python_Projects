{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "FIfa_Index_Scraping_&_Reporting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BWiJw7ivUw6",
        "colab_type": "text"
      },
      "source": [
        "#**Time series Reports of Premier League**\n",
        "**Report of Premier League's players and Teams changes over the season 2019/2020**\n",
        "\n",
        "Notebook made by:\n",
        "> Marcelo Landivar & Adam Svenson \n",
        "\n",
        "Open this notebook in Google Colaboratory:   \n",
        ">[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1_RjRfLW-Hw29PT3PpX0mxZE6TdkHE4z8/view?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXdDa1QJv9jo",
        "colab_type": "text"
      },
      "source": [
        "###**Notebook description:**\n",
        "\n",
        "The notebook has as a target to scrape the https://www.fifaindex.com/ website for player indexes over time using BeautifulSoup. The steps are the following:\n",
        "\n",
        "1. Scrape the website for the information we want.\n",
        "2. Save that information into a json format to easily access it.\n",
        "3. Aggregate the data based on teams to get some interesting metrics.\n",
        "4. Generate plots to be able to see the development of teams over time and team vs. team.\n",
        "5. Save these plots as a pdf output. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2wjN4p_yp-J",
        "colab_type": "text"
      },
      "source": [
        "###**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLIbhCkGYE5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from matplotlib.backends.backend_pdf import PdfPages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VPdwnShuQIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "59c3ca0b-d826-4da5-f879-2cb5ffa9f6cc"
      },
      "source": [
        "!pip install PyPDF2\n",
        "from PyPDF2 import PdfFileMerger"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=379018652d818349cbcc00f34ce9067e0a7a84ef4447fcdd04f39f0f34336e63\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMIrAmZ-yt12",
        "colab_type": "text"
      },
      "source": [
        "###**Web Scraping and Saving it into a JSON file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VacoNWwJYE5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building a function that gets all the links that we need to do the scraping\n",
        "def get_links(base_url, url_to_search):\n",
        "  #getting the links for all the different teams to add to the base_url\n",
        "  response = requests.get(url_to_search)\n",
        "  soup = BeautifulSoup(response.content,\"html.parser\")\n",
        "\n",
        "  df_teams_links = pd.DataFrame(columns=['links', 'teams'])\n",
        "\n",
        "  links = soup.find_all('td',{'data-title':'Name'})\n",
        "\n",
        "  for x in links:\n",
        "    p = x.find('a', {'class':'link-team'}, href=True)\n",
        "    df_teams_links = df_teams_links.append({'links':p.get('href'), 'teams':x.text}, ignore_index=True)\n",
        "\n",
        "    #defining the different links\n",
        "    final_url = []\n",
        "\n",
        "    for pages in df_teams_links.links:\n",
        "        f = base_url+str(pages)\n",
        "        final_url.append(f)\n",
        "    \n",
        "    df_teams_links['final_url'] = final_url\n",
        "  \n",
        "  return df_teams_links"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZVbOP0U0byH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_to_search = \"https://www.fifaindex.com/teams/?league=13&order=desc\"\n",
        "base_url = \"https://www.fifaindex.com\"\n",
        "df_teams_links = get_links(base_url, url_to_search)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANOtaWhfLuLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WAIT ARE WE  EVEN USING  THIS ONE?\n",
        "# function for creating the json structure that  wewant \n",
        "def get_json_data(links: pd.DataFrame, base_url):\n",
        "\n",
        "  dates = dict()\n",
        "  for i in links.teams:\n",
        "    dates[str(i)] = { # each team will be a key in the json and have dates, links,players as subs underneath\n",
        "              'Dates':[], \n",
        "              'links':[],\n",
        "              'Player':[], \n",
        "              'Score':[]\n",
        "              }\n",
        "\n",
        "  for i, team in links.iterrows(): \n",
        "    new_request = requests.get(team.final_url)\n",
        "    soup = BeautifulSoup(new_request.content, 'html.parser')\n",
        "    for links in soup.find_all('a', class_='dropdown-item', href=True): # gets all the dates links we need\n",
        "      if links['href'].startswith(str(team.links)+'fifa20'):\n",
        "          dates[str(team.teams)]['Dates'].append(links.text), dates[str(team.teams)]['links'].append(base_url+str(links['href']))\n",
        "    \n",
        "    for x in dates[str(team.teams)]['links']:\n",
        "      scores = []\n",
        "      players = []\n",
        "      request = requests.get(x)\n",
        "\n",
        "      #looping over each URL and doing the actions we define below\n",
        "      content = request.content\n",
        "      soup2 = BeautifulSoup(content,\"html.parser\")\n",
        "\n",
        "      #getting name of each player in the different teams\n",
        "      f = soup2.find_all(\"td\",{\"data-title\":\"Name\"})\n",
        "      for x in f:\n",
        "          x = x.text\n",
        "          players.append(x)\n",
        "      dates[team.teams]['Player'].append(players)\n",
        "      \n",
        "\n",
        "      # getting score of each player in each team\n",
        "      score1 = soup2.find_all(\"td\",{\"data-title\":\"OVR / POT\"})\n",
        "      for x in score1:\n",
        "          x = x.text\n",
        "          x = int(x[:-2])\n",
        "          scores.append(x)\n",
        "      dates[team.teams]['Score'].append(scores)\n",
        "\n",
        "\n",
        "  \n",
        "  return dates\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzYvlG7CEXM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = get_json_data(df_teams_links, base_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye5Pcy6z34dZ",
        "colab_type": "text"
      },
      "source": [
        "###**Saving Data and preparing the Data for Reporting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNDeiDO_Vamd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_json_file(path, file_name):\n",
        "  with open(os.path.join(path, file_name), 'w') as f:\n",
        "      json.dump(dates, f)\n",
        "\n",
        "def import_json_dates(path):\n",
        "  with open(path) as data:\n",
        "    dates = json.load(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWKn9oMDEkel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/data (1).json') as j:\n",
        "  dates =json.load(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExyX_FSuxT5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Order of teams in json\n",
        "# 1. 'Manchester City',\n",
        "# 2. 'Liverpool',\n",
        "# 3. 'Tottenham Hotspur',\n",
        "# 4. 'Manchester United',\n",
        "# 5. 'Chelsea'\n",
        "# 6. 'Arsenal',\n",
        "# 7. 'Leicester City',\n",
        "# 8. 'West Ham United',\n",
        "# 9. 'Everton',\n",
        "# 10. 'Wolverhampton Wanderers',\n",
        "# 11. 'Watford',\n",
        "# 12. 'Newcastle United',\n",
        "# 13. 'Crystal Palace'\n",
        "# 14. 'AFC Bournemouth'\n",
        "# 15. 'Burnley'\n",
        "# 16. 'Aston Villa',\n",
        "# 17. 'Southampton'\n",
        "# 18. 'Brighton & Hove Albion'\n",
        "# 19. 'Sheffield United',\n",
        "# 20. 'Norwich City'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvhi6PE0Yd44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the average for each date for each team\n",
        "def get_timeseries_table(dates, df_links:pd.DataFrame):\n",
        "  \n",
        "  'Create the timeseries Data Frame'\n",
        "  df_timeseries = pd.DataFrame(columns=[i for i in df_links.teams])\n",
        "  df_timeseries['Date'] = dates['Manchester United']['Dates']\n",
        "  df_timeseries = df_timeseries.set_index('Date')\n",
        "  df_timeseries.index = pd.to_datetime(df_timeseries.index)\n",
        "\n",
        "  'Populate the DataFrame'\n",
        "  for x in df_links.teams:\n",
        "    for i in range(len(dates[str(x)]['Dates'])):\n",
        "      y = round(sum(dates[str(x)]['Score'][i])/len(dates[str(x)]['Score'][i]), 5)\n",
        "      df_timeseries.loc[dates['Manchester United']['Dates'][i],str(x)] = y\n",
        "\n",
        "  df_timeseries['global_avg'] = df_timeseries.mean(axis=1)\n",
        "  df_timeseries.index = pd.to_datetime(df_timeseries.index)\n",
        "\n",
        "  return df_timeseries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F5b-4Nr-hC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_timeseries = get_timeseries_table(dates, df_teams_links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulS4pRvV3_09",
        "colab_type": "text"
      },
      "source": [
        "###**Generating the Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ9FUJNGMngb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating plot for all teams over time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def generate_report(df_timeseries:pd.DataFrame, path, file_name):\n",
        "\n",
        "  fig1, ax = plt.subplots(1, figsize=(20,15))\n",
        "  ax.plot(df_timeseries.iloc[:,:-1])\n",
        "  ax.plot(df_timeseries.iloc[:,-1:], linewidth=4.0, color='k',linestyle='dashed')  #global average line\n",
        "  tick_spacing = 2\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
        "  ax.set_ylim(ymin=65, ymax=83)\n",
        "  ax.set_ylabel('Score')\n",
        "  ax.set_title('Average score over time')\n",
        "  ax.legend(df_timeseries.columns, loc='upper right')\n",
        "  plt.close(fig1) \n",
        "\n",
        "  new_df = pd.DataFrame(df_timeseries.mean(axis=0))\n",
        "  new_df = new_df.sort_values(by= 0, ascending=False)\n",
        "  new_df = new_df.reset_index()\n",
        "\n",
        "  # generating overall plot with  average in red\n",
        "  y = new_df.iloc[:,1]\n",
        "  x = new_df.iloc[:,0]\n",
        "\n",
        "  fig2, ax = plt.subplots(1, figsize=(15,10))\n",
        "  plt.xticks(rotation=90)\n",
        "  test = ax.bar(x,y)\n",
        "  test[10].set_color('r')\n",
        "  plt.close(fig2) \n",
        "\n",
        "  pp = PdfPages('report_PL.pdf')\n",
        "  pp.savefig(fig1)\n",
        "  pp.savefig(fig2)\n",
        "\n",
        "  pp.close()\n",
        "\n",
        "  tick_spacing = 3\n",
        "  cols_plot = [i for i in df_timeseries.columns]\n",
        "  axes = df_timeseries[cols_plot].plot(alpha=1, linestyle='solid', figsize=(25, 35), subplots=True)\n",
        "  for ax in axes:\n",
        "    hey = ax.set_ylabel('Score')\n",
        "    hey = ax.set_ylim(ymin=65, ymax=80)\n",
        "    hey = ax.yaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
        "  plt.savefig('individual_teams_evolution.pdf')\n",
        "  plt.close() \n",
        "\n",
        "  \n",
        "  # merging the pdfs into one\n",
        "  pdfs = ['report_PL.pdf', 'individual_teams_evolution.pdf']\n",
        "  merger = PdfFileMerger()\n",
        "\n",
        "  for pdf in pdfs:\n",
        "      merger.append(pdf)\n",
        "\n",
        "  merger.write(os.path.join(path, file_name))\n",
        "  merger.close()\n",
        "\n",
        "  # removing unnecessary files we don't need after merge\n",
        "  os.remove(os.path.join(os.getcwd(), \"individual_teams_evolution.pdf\"))\n",
        "  os.remove(os.path.join(os.getcwd(), \"report_PL.pdf\"))\n",
        "\n",
        "  return print('Report Generated and Saved')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMVW5pimJGPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5f6c1e8-ed5e-41e3-c7d2-20d3c44c3c42"
      },
      "source": [
        "generate_report(df_timeseries, path='/content/sample_data', file_name='Report_PL_2020.pdf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report Generated and Saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}